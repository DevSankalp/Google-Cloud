{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=!gcloud config get-value project\n",
    "PROJECT=PROJECT[0]\n",
    "BUCKET = PROJECT + '-dsongcp'\n",
    "import os\n",
    "os.environ['BUCKET'] = PROJECT + '-dsongcp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindays = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('gs://{}/flights/trainday.csv'.format(BUCKET))\n",
    "traindays.createOrReplaceTempView('traindays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindays.createOrReplaceTempView('traindays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * from traindays LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'gs://{}/flights/tzcorr/all_flights-00000-*'.format(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = spark.read.json(inputs)\n",
    "flights.createOrReplaceTempView('flights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainquery = \"\"\"\n",
    "SELECT\n",
    "  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n",
    "FROM flights f\n",
    "JOIN traindays t\n",
    "ON f.FL_DATE == t.FL_DATE\n",
    "WHERE\n",
    "  t.is_train_day == 'True'\n",
    "\"\"\"\n",
    "traindata = spark.sql(trainquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainquery = \"\"\"\n",
    "SELECT\n",
    "DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n",
    "FROM flights f\n",
    "JOIN traindays t\n",
    "ON f.FL_DATE == t.FL_DATE\n",
    "WHERE\n",
    "t.is_train_day == 'True' AND\n",
    "f.dep_delay IS NOT NULL AND \n",
    "f.arr_delay IS NOT NULL\n",
    "\"\"\"\n",
    "traindata = spark.sql(trainquery)\n",
    "traindata.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainquery = \"\"\"\n",
    "SELECT\n",
    "  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\n",
    "FROM flights f\n",
    "JOIN traindays t\n",
    "ON f.FL_DATE == t.FL_DATE\n",
    "WHERE\n",
    "  t.is_train_day == 'True' AND\n",
    "  f.CANCELLED == 'False' AND \n",
    "  f.DIVERTED == 'False'\n",
    "\"\"\"\n",
    "traindata = spark.sql(trainquery)\n",
    "traindata.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_example(fields):\n",
    "    return LabeledPoint(\\\n",
    "              float(fields['ARR_DELAY'] < 15), #ontime? \\\n",
    "              [ \\\n",
    "                  fields['DEP_DELAY'], \\\n",
    "                  fields['TAXI_OUT'],  \\\n",
    "                  fields['DISTANCE'],  \\\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = traindata.rdd.map(to_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = LogisticRegressionWithLBFGS.train(examples, intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE='gs://' + BUCKET + '/flights/sparkmloutput/model'\n",
    "os.system('gsutil -m rm -r ' + MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel.save(sc, MODEL_FILE)\n",
    "print('{} saved'.format(MODEL_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionModel\n",
    "lrmodel = LogisticRegressionModel.load(sc, MODEL_FILE)\n",
    "lrmodel.setThreshold(0.7)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
